# ğŸ“Œ Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# ğŸ“¥ Load Dataset
df = pd.read_csv("traffic volume.csv")  # Ensure the file is in the same folder

# â³ Convert Date & Time
df['datetime'] = pd.to_datetime(df['date'] + ' ' + df['Time'])
df['year'] = df['datetime'].dt.year
df['month'] = df['datetime'].dt.month
df['day'] = df['datetime'].dt.day
df['hours'] = df['datetime'].dt.hour
df['minutes'] = df['datetime'].dt.minute
df['seconds'] = df['datetime'].dt.second

# ğŸ§¹ Clean Data
df.drop(columns=['date', 'Time', 'datetime'], inplace=True)
df['holiday'] = df['holiday'].astype('category').cat.codes
df['weather'] = df['weather'].astype('category').cat.codes
df.dropna(inplace=True)

# ğŸ§¾ Summary
print("ğŸ“ Dataset Info:")
print(df.info())
print("\nğŸ“Š Statistical Overview:")
print(df.describe())

# ğŸ“ˆ Correlation Heatmap
plt.figure(figsize=(12, 6))
sns.heatmap(df.corr(), annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Correlation Heatmap of Features")
plt.show()

# â± Hourly Volume Trend
plt.figure(figsize=(10, 5))
sns.lineplot(x='hours', y='traffic_volume', data=df)
plt.title("Hourly Traffic Volume Trend")
plt.xlabel("Hour of Day")
plt.ylabel("Traffic Volume")
plt.grid(True)
plt.show()

# ğŸŒ¦ Volume by Weather
plt.figure(figsize=(10, 5))
sns.boxplot(x='weather', y='traffic_volume', data=df)
plt.title("Traffic Volume by Weather Type")
plt.xlabel("Weather Code")
plt.ylabel("Traffic Volume")
plt.show()

# ğŸ§  Model Features & Target
features = ['holiday', 'temp', 'rain', 'snow', 'weather',
            'year', 'month', 'day', 'hours', 'minutes', 'seconds']
X = df[features]
y = df['traffic_volume']

# ğŸ“¤ Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ğŸ¤– Train Random Forest
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# ğŸ§¾ Predictions
y_pred = model.predict(X_test)

# ğŸ§® Evaluation
rmse = mean_squared_error(y_test, y_pred, squared=False)
r2 = r2_score(y_test, y_pred)
print(f"\nâœ… Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"âœ… RÂ² Score: {r2:.4f}")

# ğŸ“Š Feature Importances
importances = model.feature_importances_
feature_names = X.columns
indices = np.argsort(importances)

plt.figure(figsize=(10, 6))
plt.title("Feature Importances")
plt.barh(range(len(indices)), importances[indices], align='center')
plt.yticks(range(len(indices)), [feature_names[i] for i in indices])
plt.xlabel("Relative Importance")
plt.grid(True)
plt.show()

# ğŸ” Actual vs Predicted (sample)
plt.figure(figsize=(12, 6))
plt.plot(y_test[:100].values, label="Actual", linewidth=2)
plt.plot(y_pred[:100], label="Predicted", linewidth=2)
plt.title("Traffic Volume: Actual vs Predicted (Sample of 100)")
plt.xlabel("Sample Index")
plt.ylabel("Traffic Volume")
plt.legend()
plt.grid(True)
plt.show()
