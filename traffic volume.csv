# ---------------------------------------
# ğŸ“¦ Import required libraries
# ---------------------------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import os

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# ---------------------------------------
# ğŸ“¥ Load dataset
# ---------------------------------------
print("ğŸ”¹ Loading dataset...")
df = pd.read_csv("traffic volume.csv")

print("âœ… Data loaded successfully.")
print("ğŸ“Š Dataset shape:", df.shape)
print(df.head())

# ---------------------------------------
# ğŸ§¹ Clean & preprocess data
# ---------------------------------------

# Step 1: Combine 'date' and 'Time' into single datetime
df['datetime'] = pd.to_datetime(df['date'] + ' ' + df['Time'])

# Step 2: Extract time-based features
df['year'] = df['datetime'].dt.year
df['month'] = df['datetime'].dt.month
df['day'] = df['datetime'].dt.day
df['hours'] = df['datetime'].dt.hour
df['minutes'] = df['datetime'].dt.minute
df['seconds'] = df['datetime'].dt.second

# Step 3: Drop unused columns
df.drop(columns=['date', 'Time', 'datetime'], inplace=True)

# Step 4: Encode categorical features
df['holiday'] = df['holiday'].astype('category').cat.codes
df['weather'] = df['weather'].astype('category').cat.codes

# Step 5: Drop missing values
df.dropna(inplace=True)

print("\nâœ… Cleaned DataFrame:")
print(df.head())

# ---------------------------------------
# ğŸ“ˆ Exploratory Data Analysis (EDA)
# ---------------------------------------

print("\nğŸ“Š Running basic data analysis...")

# Traffic volume by hour
plt.figure(figsize=(10, 5))
sns.lineplot(x='hours', y='traffic_volume', data=df, ci=None)
plt.title("Average Traffic Volume by Hour")
plt.xlabel("Hour of Day")
plt.ylabel("Traffic Volume")
plt.grid(True)
plt.tight_layout()
plt.savefig("traffic_volume_by_hour.png")
plt.show()

# Correlation heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Matrix")
plt.tight_layout()
plt.savefig("correlation_heatmap.png")
plt.show()

# ---------------------------------------
# âœ‚ï¸ Feature Selection
# ---------------------------------------
features = ['holiday', 'temp', 'rain', 'snow', 'weather',
            'year', 'month', 'day', 'hours', 'minutes', 'seconds']
target = 'traffic_volume'

X = df[features]
y = df[target]

# ---------------------------------------
# ğŸ¯ Train-test split
# ---------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

print("\nğŸ§ª Training samples:", len(X_train))
print("ğŸ§ª Testing samples:", len(X_test))

# ---------------------------------------
# ğŸš€ Model training
# ---------------------------------------
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

print("\nâœ… Model trained successfully.")

# ---------------------------------------
# ğŸ“Š Predictions & Evaluation
# ---------------------------------------
y_pred = model.predict(X_test)

rmse = mean_squared_error(y_test, y_pred, squared=False)
r2 = r2_score(y_test, y_pred)

print(f"ğŸ“‰ Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"ğŸ“ˆ RÂ² Score: {r2:.4f}")

# ---------------------------------------
# ğŸ”„ Compare actual vs predicted
# ---------------------------------------
results_df = pd.DataFrame({
    'Actual': y_test.values,
    'Predicted': y_pred
})

# Save to CSV (optional)
results_df.to_csv("traffic_volume_predictions.csv", index=False)

# Plot
plt.figure(figsize=(12, 5))
plt.plot(results_df['Actual'][:100], label='Actual', linewidth=2)
plt.plot(results_df['Predicted'][:100], label='Predicted', linewidth=2)
plt.title("Actual vs Predicted Traffic Volume (Sample 100)")
plt.xlabel("Sample")
plt.ylabel("Traffic Volume")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("prediction_comparison.png")
plt.show()

# ---------------------------------------
# ğŸ’¾ Save model
# ---------------------------------------
with open("model.pkl", "wb") as f:
    pickle.dump(model, f)

print("\nğŸ“¦ model.pkl has been saved!")

# ---------------------------------------
# ğŸ“Š Save feature importances
# ---------------------------------------
importances = pd.Series(model.feature_importances_, index=features)
importances = importances.sort_values(ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x=importances.values, y=importances.index, palette="viridis")
plt.title("Feature Importance")
plt.xlabel("Importance Score")
plt.tight_layout()
plt.savefig("feature_importance.png")
plt.show()
